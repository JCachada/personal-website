<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>You Don&#39;t Own My Brain - The Problem With AI FUD | jo√£o&#39;s website üêü</title>
<meta name="title" content="You Don&#39;t Own My Brain - The Problem With AI FUD" />
<meta name="description" content="Why a lot of the current discourse on AI is silly." />
<meta name="keywords" content="LLM,ai,opinion,development," />


<meta property="og:title" content="You Don&#39;t Own My Brain - The Problem With AI FUD" />
<meta property="og:description" content="Why a lot of the current discourse on AI is silly." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jcachada.dev/weblog/you-dont-own-my-brain-the-problem-with-ai-fud/" /><meta property="og:image" content="https://jcachada.dev/images/share.png" /><meta property="article:section" content="weblog" />
<meta property="article:published_time" content="2025-08-07T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-08-07T00:00:00+00:00" /><meta property="og:site_name" content="Jo√£o Cachada&#39;s website" />




<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://jcachada.dev/images/share.png" /><meta name="twitter:title" content="You Don&#39;t Own My Brain - The Problem With AI FUD"/>
<meta name="twitter:description" content="Why a lot of the current discourse on AI is silly."/>



<meta itemprop="name" content="You Don&#39;t Own My Brain - The Problem With AI FUD">
<meta itemprop="description" content="Why a lot of the current discourse on AI is silly."><meta itemprop="datePublished" content="2025-08-07T00:00:00+00:00" />
<meta itemprop="dateModified" content="2025-08-07T00:00:00+00:00" />
<meta itemprop="wordCount" content="3684"><meta itemprop="image" content="https://jcachada.dev/images/share.png" />
<meta itemprop="keywords" content="LLM,ai,opinion,development," />
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  :root {
     
    --flexoki-black: #100F0F;
    --flexoki-paper: #FFFCF0;
    
     
    --flexoki-50: #F2F0E5;
    --flexoki-100: #E6E4D9;
    --flexoki-150: #DAD8CE;
    --flexoki-200: #CECDC3;
    --flexoki-300: #B7B5AC;
    --flexoki-600: #6F6E69;
    --flexoki-850: #343331;
    --flexoki-950: #1C1B1A;
    
     
    --flexoki-dark-50: #1C1B1A;
    --flexoki-dark-100: #282726;
    --flexoki-dark-150: #343331;
    --flexoki-dark-200: #403E3C;
    --flexoki-dark-300: #575653;
    
     
    --flexoki-red: #AF3029;
    --flexoki-orange: #BC5215;
    --flexoki-yellow: #AD8301;
    --flexoki-green: #66800B;
    --flexoki-cyan: #24837B;
    --flexoki-blue: #205EA6;
    --flexoki-purple: #5E409D;
    --flexoki-magenta: #A02F6F;
    
     
    --flexoki-red-dark: #D14D41;
    --flexoki-orange-dark: #DA702C;
    --flexoki-yellow-dark: #D0A215;
    --flexoki-green-dark: #879A39;
    --flexoki-cyan-dark: #3AA99F;
    --flexoki-blue-dark: #4385BE;
    --flexoki-purple-dark: #8B7EC8;
    --flexoki-magenta-dark: #CE5D97;
  }

  body {
    font-family: Verdana, sans-serif;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: var(--flexoki-paper);
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.7;
    letter-spacing: 0.01em;
    color: var(--flexoki-600);
    font-size: 16px;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: var(--flexoki-black);
    letter-spacing: -0.02em;
  }

  h1 {
    font-size: 2.2em;
    margin: 0.5em 0 0.75em 0;
    line-height: 1.2;
  }

  h2 {
    font-size: 1.6em;
    margin: 1.4em 0 0.6em 0;
    line-height: 1.3;
  }

  h3 {
    font-size: 1.3em;
    margin: 1.3em 0 0.5em 0;
    line-height: 1.4;
  }

  h4, h5, h6 {
    font-size: 1.1em;
    margin: 1.2em 0 0.4em 0;
    line-height: 1.4;
  }

  a {
    color: var(--flexoki-blue);
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
    background-color: var(--flexoki-50);
    color: var(--flexoki-black);
    border: 1px solid var(--flexoki-200);
  }

  input {
    font-size: 16px;
    background-color: var(--flexoki-50);
    color: var(--flexoki-black);
    border: 1px solid var(--flexoki-200);
  }

  p {
    margin: 1.2em 0;
    line-height: 1.7;
  }

  content {
    line-height: 1.7;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: var(--flexoki-100);
    color: var(--flexoki-black);
  }

  pre code {
    color: var(--flexoki-black);
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
    background-color: var(--flexoki-50);
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 3px solid var(--flexoki-300);
    color: var(--flexoki-600);
    padding-left: 24px;
    margin: 1.5em 0;
    font-style: italic;
    line-height: 1.8;
  }

  footer {
    text-align: left;
  }

  .helptext {
    color: var(--flexoki-300);
    font-size: small;
  }

  .errorlist {
    color: var(--flexoki-orange);
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
    margin: 1.5em 0;
  }

  ul.blog-posts li {
    display: flex;
    margin-bottom: 0.1em;
    line-height: 1.6;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
    font-size: 0.9em;
    color: var(--flexoki-300);
  }

  ul.blog-posts li a:visited {
    color: var(--flexoki-purple);
  }

  @media (prefers-color-scheme: light) {
    body {
      background-color: var(--flexoki-dark-50);
      color: var(--flexoki-200);
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: var(--flexoki-paper);
    }

    a {
      color: var(--flexoki-blue-dark);
    }

    code {
      background-color: var(--flexoki-dark-200);
      color: var(--flexoki-paper);
    }

    pre code {
      color: var(--flexoki-paper);
      background-color: var(--flexoki-dark-100);
    }

    blockquote {
      color: var(--flexoki-300);
      border-left-color: var(--flexoki-dark-300);
    }

    textarea,
    input {
      background-color: var(--flexoki-dark-150);
      color: var(--flexoki-paper);
      border-color: var(--flexoki-dark-300);
    }

    .helptext {
      color: var(--flexoki-dark-300);
    }

    ul.blog-posts li a:visited {
      color: var(--flexoki-purple-dark);
    }
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: var(--flexoki-dark-50);
      color: var(--flexoki-200);
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: var(--flexoki-paper);
    }

    a {
      color: var(--flexoki-blue-dark);
    }

    code {
      background-color: var(--flexoki-dark-200);
      color: var(--flexoki-paper);
    }

    pre code {
      color: var(--flexoki-paper);
      background-color: var(--flexoki-dark-100);
    }

    blockquote {
      color: var(--flexoki-300);
      border-left-color: var(--flexoki-dark-300);
    }

    textarea,
    input {
      background-color: var(--flexoki-dark-150);
      color: var(--flexoki-paper);
      border-color: var(--flexoki-dark-300);
    }

    .helptext {
      color: var(--flexoki-dark-300);
    }

    ul.blog-posts li a:visited {
      color: var(--flexoki-purple-dark);
    }
  }

  summary.clickable-header.big-top-pull {
    display: inline;
    cursor: pointer;
    position: relative;
    margin-bottom: -100px;
    margin-top: -20px;
  }

  summary.clickable-header.small-top-pull {
    display: inline;
    cursor: pointer;
    position: relative;
    margin-bottom: -100px;
    margin-top: -5px;
  }

  .clickable-header h4::before {
    content: "‚ñ∂";
    margin-right: 5px;
  }

  details[open] .clickable-header h4::before {
    content: "‚ñº";
  }
</style>
</head>

<body>
  <header><a href="/" class="title">
  <h2>jo√£o&#39;s website üêü</h2>
</a>
<nav><a href="/">Home & About</a>


<a href="/weblog">Weblog</a>


<a href="/not-a-product">Not a Product</a>


<a href="/say-hi">Say Hi</a>
</nav>
</header>
  <main>

<h1>You Don&#39;t Own My Brain - The Problem With AI FUD</h1>
<p>
  <i>
    <time datetime='2025-08-07' pubdate>
      07 Aug, 2025
    </time>
  </i>
</p>

<content>
  <p>Two days ago, Github&rsquo;s CEO Thomas Dohmke added his voice to the many that came before to say:</p>
<blockquote>
<p>Either you have to embrace the Al, or you get out of your career. <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>This is not the first time I&rsquo;ve heard this kind of discourse, usually from people who haven&rsquo;t done a day of software engineering in their life. And I hate it. So this post is about why it&rsquo;s silly, why they&rsquo;re wrong to address you in these terms and why, if you&rsquo;re a developer in the software field, you have a little bit less reason to worry than they&rsquo;d like you to think.</p>
<p>This is not a post bashing Large Language Models as a technology. There&rsquo;s a lot about them that I think can be challenged, and I will mention a few of those things, as well as my personal experience with the tech, in this very post. But the point is not to have a discussion about whether or not I think LLMs can be redeemed, or what their moral standing is. Instead what I want to express is that, regardless of where you stand on LLMs, this way of talking about them is wrong. It&rsquo;s, at best, a misguided and poorly communicated attempt to externalize real, tangible fears, and at worst a malicious, money-driven power grab and violation of workers&rsquo; rights.</p>
<h2 id="dot-dot-dot-com">Dot Dot Dot [Com]</h2>
<p>I suspect most people old enough today to own a credit card and buy a subscription to an LLM have been through at least a few Big Tech hype cycles. It shouldn&rsquo;t be controversial to say that they usually don&rsquo;t pan out. The last one I can remember, off the top of my head, was the VR promises with Oculus, the Metaverse, the HTC Vive, and the idea that we were finally entering the next era of truly immersive video games; that a qualitative barrier of some sort had been crossed, leaving only the grunt work to be done, the necessary-but-boring type of iteration on small things like the comfort of the headsets, their price, and getting game developers to actually make games for these systems that, when done - and it was only a matter of time! - would change the face of video games forever.</p>
<p>Well, video games don&rsquo;t look very changed, and I don&rsquo;t see a lot of Game of the Year games coming out for Oculus.</p>
<p>I think of games first because, in a lot of ways, that is my world - but if I strain just a little bit, I also think of cryptocurrency (with its unrealized promise to revolutionize finance by decentralizing it), full self driving (which Tesla promised in 2015 would arrive in 2018 <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, but has still not arrived), or NFTs (which promised&hellip; something? To someone? I don&rsquo;t actually understand how anyone ever fell for that one). All of those share at least a couple of characteristics. The first one is that, however you think of the state those technologies are in today, they have gloriously failed to live up to the predictions about what kind of revolution they would bring. The second one is not just that those predictions existed in the first place, but that they all took on this same kind of tone when advertising themselves: a tone that goes beyond the patronizing and sanctimonious.</p>
<p>Because that&rsquo;s the thing, isn&rsquo;t it? None of these are worded as &ldquo;you should use this if you want to stay at the forefront of your profession.&rdquo; Thomas Dohmke and friends are not sharing their heartfelt view that LLMs will skyrocket your productivity. They&rsquo;re saying, very deliberately: get in, or you&rsquo;ll be forced out. They&rsquo;re saying that if you disagree with them, they will stonewall you. That if you have reservations, they will make sure you&rsquo;re culled. The implication is that at the end of this road, should you dare to question the value proposition of the LLM or put up some barriers to your usage of it, that puts you on the fast track to financial ruin. Your career will be irreversibly damaged. You will fall behind and never catch up until, maybe, you see the light of day and grovel to jump back on the train. And maybe, if you&rsquo;re lucky, the magnanimous supercomputer gods won&rsquo;t have moved so far past you that catching up is impossible. But it&rsquo;s always a risk, so you better get on that train from the get-go.</p>
<p>This is the same discourse that crypto had surrounding it, and to an extent still does; you better get on board, or you&rsquo;ll not only miss the chance to get rich, but you&rsquo;ll fundamentally not understand the new financial system the world is rebuilt around! You&rsquo;ll be like a second class citizen!</p>
<p>Buy this stylized picture of an ape with a beanie, otherwise do you even believe in progress?</p>
<h2 id="what-am-i-your-dad">What am I, your dad?</h2>
<p>Here&rsquo;s a regular conversation that happens whenever I start managing someone new:</p>
<p>&ldquo;Hey,&rdquo; they say, or drop in a slack message. &ldquo;I have a doctor&rsquo;s appointment next week, so I won&rsquo;t be in the office between 2 and 3 p.m. I hope that&rsquo;s okay and I&rsquo;ll make up for it when I get back.&rdquo;</p>
<p>I check to see if we had a meeting scheduled over that time slot - we didn&rsquo;t. I check their calendar to see if they&rsquo;re skipping a meeting with someone else that I&rsquo;m not a part of (maybe they feel guilty and want their manager to tell them it&rsquo;s okay) - they&rsquo;re not. I check the JIRA board to make sure I didn&rsquo;t accidentally assign the new joiner a buttload of work during their onboarding, and what they&rsquo;re really telling me is &ldquo;sorry but I can&rsquo;t deliver this ticket on time&rdquo; - nope, nothing like that. So I sigh and type out the usual response:</p>
<p>&ldquo;What am I, your dad?&rdquo;</p>
<p>Okay, maybe I word it a little bit better than that - I do know how to be professional.</p>
<p>But it does happen that these new joiners, without fail, think they have to get my permission or let me know about when they&rsquo;re going to step out, especially when it won&rsquo;t affect me in any way. This is understandable when it happens with starry-eyed, straight out of college junior engineers, but it also happens with seasoned, multiple-decades-in-the-industry veterans. It happens with 20 year olds and 50 year olds. It happens with people who are actually old enough to be <em>my</em> dad. And sure, some of it is that people are used to the physical office, where their absence will be noticed. It would be weird not to tell your boss why you won&rsquo;t be at your desk. But I work at a remote company. We don&rsquo;t have an office. And I cannot actually believe that this behavior happens this consistently just because of politeness. People are being trained to do this. They&rsquo;re scared of the consequences if they don&rsquo;t, and there&rsquo;s at least an implicit understanding that the company is buying your <em>time</em>.</p>
<p>So imagine their surprise when I tell them some variation of: &ldquo;I don&rsquo;t actually care what you do with your time. As long as you&rsquo;re here for the shared meetings, your tickets get done on time, and you aren&rsquo;t rushing them to go look at Vines (or whatever the kids do nowadays: I&rsquo;m hip), I don&rsquo;t really care if you&rsquo;re at the beach at 4 PM.&rdquo;</p>
<p>For the first few weeks they don&rsquo;t quite believe me. They sometimes still reach out, letting me know they&rsquo;ll have to step out, and I gently poke fun at them. I don&rsquo;t mind being informed, but I do want my reports to know that I don&rsquo;t actually care how they&rsquo;re doing the things I ask them to do.</p>
<p>And of course, if people are given this respect, they are also given the responsibility to handle the consequences. If you&rsquo;re deciding how to manage your time, and you mess up your deadlines, or don&rsquo;t deliver high quality enough work, we&rsquo;re going to have a chat. That&rsquo;s the flipside of this approach.</p>
<h2 id="you-should-take-better-care-of-yourself">You should take better care of yourself</h2>
<p>Okay, but why am I telling you all of this? Do I just want to brag about how cool a manager I am?</p>
<p>Well, yeah.</p>
<p>But also, the type of post that I&rsquo;m writing this whole rant against is sort of the other side of the coin. Now, imagine your boss - not just your boss, your CEO - comes to you and says:</p>
<p>&ldquo;So, I think going to the gym really makes people more productive, so you either start doing it daily or you&rsquo;re out.&rdquo;</p>
<p>You&rsquo;d think that&rsquo;s crazy, right? A gross overreach of power, illegal depending on where you&rsquo;re located. Who&rsquo;s this person, and where to they get off trying to step into your personal lifestyle and tell you how to live your life? Yes, we&rsquo;d all be a lot more productive if we got 8 hours of sleep every night and started the day with a glass of water, but I live in a free country! It&rsquo;s my fundamental human right to be dehydrated and sleep deprived because someone sent me a funny cat video when I was getting ready for bed, and I ended up doomscrolling for three hours.</p>
<p>Okay, let&rsquo;s bring it back to LLMs.</p>
<blockquote>
<p>Either you have to embrace the Al, or you get out of your career. <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</blockquote>
<p>This is not advice. This is not a concerned citizen trying to make sure you don&rsquo;t fall by the wayside. This is someone trying to hammer you with power, fear, uncertainty, and doubt about your future if you don&rsquo;t comply. This is someone saying &ldquo;do this, or else&rdquo;. That&rsquo;s just not something I&rsquo;m comfortable letting Big Tech, or anyone, decide for me - and you shouldn&rsquo;t either.</p>
<p>What this particular brand of LLM discourse represents is not a genuine belief that you will not be competitive without buying in to the tech, but a belief that the goalposts can be moved. That you can now tell employees not just what to do, but how to think about things. That you can encroach past the borders of an employer/employee relationship and mold your subordinates into mirrors of your value system.</p>
<p>Here&rsquo;s the thing - if people were actually worried about the necessity of LLM usage to keep up with the market, this isn&rsquo;t the angle they&rsquo;d take. You don&rsquo;t come to someone and say &ldquo;use Rust or else&rdquo; if you&rsquo;re worried about their code being too slow. You go to them and say &ldquo;hey, have you seen these benchmarks? Have you seen how much faster Rust is than what you&rsquo;re using? You should probably consider using it.&rdquo;</p>
<p>But they&rsquo;re not saying that, and that&rsquo;s a pretty good indicator that they&rsquo;re not actually worried about productivity as much as they&rsquo;re worried about the ability to tell you how to live your life.</p>
<h2 id="does-anyone-actually-know-what-developer-productivity-is">Does anyone actually know what developer productivity is</h2>
<p>There&rsquo;s a funny aspect of this analogy to me: if your boss was saying something like &ldquo;you need to start going to the gym every day&rdquo;, or &ldquo;you need to start meditating&rdquo;, that would actually be a somewhat more sensible thing. Don&rsquo;t get me wrong: still very out of place in a work context, but at least backed up by real, tangible, known improvements that apply to a lot of people, and so have a decent chance of working for you, too. That&rsquo;s why tech companies give you gym memberships and mental health support. It&rsquo;s not because they love you as a person (sorry), it&rsquo;s because they <em>do</em> actually make you happier, which is usually good for the company.</p>
<p>We have absolutely no idea if LLMs increase your productivity. We have absolutely no idea what productivity means. In 2023, researchers from the University of Gdansk in Poland tried to look into it through the lens of patents:</p>
<blockquote>
<p>An increasing body of empirical literature documents the puzzling mismatch between expectations related to the production and diffusion of modern digital technologies on the one hand and the poor reflection of them in official productivity records of many countries on the other. (&hellip;) By comparing AI data with productivity records we have shown that an increase in patenting and scientific activity can indeed be observed in the AI domain. However, this activity is at odds with evidence on productivity growth. Our results point towards negligible macro-level effects of AI technology production, especially of that reflected in patent records. <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
</blockquote>
<p>On the other hand, Microsoft&rsquo;s first Productivity and AI report mentioned, clearly thinking productivity is &ldquo;writing more code&rdquo;:</p>
<blockquote>
<p>Results from the studies support the hypothesis that the first versions of Copilot tools substantially increase productivity on these tasks. This productivity boost usually appeared in the studies as a meaningful increase in speed of execution without a significant decrease in quality. <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
</blockquote>
<p>Industry opinions are also divided - check out, for example, Martin Fowler&rsquo;s <a href="https://martinfowler.com/articles/exploring-gen-ai/13-role-of-developer-skills.html">thoughts</a> on the subject, or Gergely Orosz&rsquo;s great <a href="https://newsletter.pragmaticengineer.com/p/software-engineering-with-llms-in-2025">write-up</a> on the current state of things.</p>
<p>Look, I don&rsquo;t know if LLMs make us more productive or not. People much smarter than me dedicate themselves to the problem of developer productivity - if you want some hints on who to follow, I recommend <a href="https://www.drcathicks.com/">Dr. Cat Hicks</a>. I can almost hear her in the background saying that we don&rsquo;t even have an agreed working definition of developer productivity, so how can we measure the impacts of LLMs on it? And on top of that, how the usefulness of tools is determined not just by the intrinsic nature of the tools, but by the environment they&rsquo;re used in as well; so maybe we should be careful with broad claims about how LLMs improve or don&rsquo;t improve developer productivity. Not to mention how young the tech is - if entropy is being introduced to code bases by using LLMs in subtle ways, that can take years to manifest itself fully.</p>
<p>I suppose that&rsquo;s all okay, because we concluded in the previous section that the people we&rsquo;re arguing against don&rsquo;t actually care about productivity.</p>
<p>In any case, I suppose here&rsquo;s where I have to tell you how I actually feel about LLMs. First, a note - it is not accidental that I keep calling them LLMs. I am particular about language  (blame my humanities background) and one thing I am certain of is that the current iteration of LLMs is not <em>intelligent</em>. They&rsquo;re very sophisticated auto-complete engines. They&rsquo;re large language models - not artificial intelligence.</p>
<p>Okay, now that I&rsquo;ve gotten you off my lawn, here&rsquo;s how I feel about LLMs:</p>
<ul>
<li>They are more useful than many of their detractors claim. They are not &ldquo;always wrong&rdquo;, &ldquo;always hallucinating&rdquo;, or &ldquo;pure slop&rdquo;. They are very useful for writing scripts I could write manually, but faster; and they are very useful for constrained tasks with defined boundaries and clear direction.</li>
<li>They are less useful than many of their proponents claim. They can&rsquo;t refactor entire codebases without so much supervision that I might as well just do it myself. And they most definitely can&rsquo;t build apps from scratch, unless you have enough engineering knowledge to begin with to spot, and stop, the hallucinations. The amount of handholding and validation they require for these sort of complex tasks makes their usage not that useful.</li>
<li>They heavily vary in usefulness depending on how you use them. I was having miserable results at first. Then, using an adapted version of <a href="https://harper.blog/2025/05/08/basic-claude-code/">this</a> method, I got better results. This might help explain why people&rsquo;s experience with them varies so much. It also might mean that the limitations I perceive in them are my own fault / lack of skill, and some people <em>can</em> refactor entire code bases or write apps from scratch using them.</li>
<li>They have found a pretty useful niche for me as a better search engine. I can&rsquo;t tell Qwant (or Google, if you&rsquo;re less of a contrarian than me) that no, that&rsquo;s not what I meant with my keywords, can you adjust the search results slightly to better match this tone? But I can do that to an LLM. And they&rsquo;re much better at going through obscure error code documentation than me and StackOverflow ever were.</li>
</ul>
<p>All in all, I would say they <em>do</em> make me slightly faster than usual. However, I have a lot of other concerns about them:</p>
<ul>
<li>Copyright issues. Models are often trained on data without consent. That is theft. This is especially bad for art. I refuse to engage with LLM art and think poorly of those who do. Art is about human connection, and we need to support artists instead of asking bots to make art for us.</li>
<li>Environmental issues. I am deeply concerned with the environmental cost related to LLMs and this is a major factor in limiting my usage of it. Yes, other things are also bad for the environment. So are LLMs, though.</li>
<li>Privacy issues. I do not trust Anthropic, OpenAI, or whoever else with my data.</li>
<li>Political issues. If you&rsquo;re the information broker, you&rsquo;re also the power broker. Facebook already heavily influenced multiple elections. I fear the idea of LLMs catering my search results to a perceived political group, targetting me, or trying to profile me in any way.</li>
<li>Long term cognitive issues. I think it&rsquo;s entirely possible LLMs, or certain ways of using them, make you dumber in the long term. I would rather not have that happen to me.</li>
</ul>
<p>And those are all incredibly valid, reasonable concerns to have about a technology. So when someone tells me: &ldquo;well, use AI or your career is done&rdquo;, they&rsquo;re not actually telling me just that. What they&rsquo;re also saying is &ldquo;whatever those other concerns you have are, you must allow them all to be sacrificed at the altar of my idea of productivity&rdquo;.</p>
<p>If you share those concerns, this is me saying: I hear you, and you&rsquo;re not crazy. Those are reasonable things to think. And even if LLMs do everything every tech bro ever promised and change the industry forever, those will still be reasonable things to think about.</p>
<h2 id="news-of-your-death-have-been-greatly-exaggerated-or-what-can-you-do-about-things">News of your death have been greatly exaggerated, or: what can you do about things</h2>
<p>I majored in Philosophy in university, which means I am pretty good at tricks to make people agree with me. I have a lot of rhetoric under my belt, and I try my best to use it for good. One of the things I learned is that if you control the question, then you control the possible answers. That&rsquo;s debating 101.</p>
<p>Let me give you an example. Let&rsquo;s look at this quote, often attributed to Mark Zuckerberg, although I could find no evidence of him actually having said it:</p>
<blockquote>
<p>We are entering a world where we will learn to coexist with AI, not as its masters, but as its collaborators.</p>
</blockquote>
<p>What lovely framing, isn&rsquo;t it?</p>
<p>If you look at that sentence, you might be tricked into thinking that the kind of questions you can ask are something like: &ldquo;How do I feel about this thing that is going to happen?&rdquo; &ldquo;How will I adapt to it when it happens?&rdquo; &ldquo;What will happen to my job when AI comes?&rdquo;</p>
<p>The thing is, those are all questions you were led to. What if, instead, we said:</p>
<blockquote>
<p>We are entering a world where we can learn to coexist with AI, not as its masters, but as its collaborators. If we want to.</p>
</blockquote>
<p>Then, the question becomes: <em>Do we want to?</em></p>
<p>Only you can answer that for yourself. But I&rsquo;m here to tell you it&rsquo;s not inevitable. I&rsquo;m not convinced LLMs are the way forward for the world. I&rsquo;m not convinced LLMs are the way forward for my job. But what I am convinced about is that if I ever have a discussion with one of my reports about the way they do their job, it will be about their <strong>outcomes</strong>. I will tell them &ldquo;hey, you&rsquo;re not hitting the targets, or doing as well as I expect you to. Let&rsquo;s talk about it and, if you want, I can try to help you get back on track.&rdquo; And then, they will decide if an LLM will help or not, and I will help them along their path to the best of my ability.</p>
<p>What I&rsquo;m also convinced about is that, as long as I continue to be productive <em>without</em> them, anyone who tries to force me to use LLMs a second more than I want to is not actually interested in my productivity. And when that is the case, there is only one possible answer:</p>
<p>Respectfully, fuck off.</p>
<p>Employers and Big Tech bros don&rsquo;t own your self, your sense of the future, or the way that you wish to interact with your work. They don&rsquo;t own your morals or the limits of how you&rsquo;re allowed to think about things. They would really like to, and they will try to issue dire warnings to make you think they do, but they don&rsquo;t.</p>
<p>They hire you to help them achieve business outcomes. They get a limited (by law, by ethics and by the notion of humanity) say in how you do this, but they don&rsquo;t get to lock you out of your career if you don&rsquo;t believe the same things they do. They have no claim to your mind. They buy your labor, not your brain.</p>
<p>You have choices about what you want your future to look like. Do not just give them away because someone told you AI is like a train coming towards you, and the clash is an inevitability. It&rsquo;s not.</p>
<p>And if they try to strongarm you into agreeing with them, I urge you to recognize it for the grift it is. There&rsquo;s really no qualitative difference between the CEO of a company heavily invested in the success of LLMs for their stock price trying to bully you into agreeing that LLMs are the only possible future, and a random Twitter user with a cartoon ape profile picture trying to convince you that paying obscene amounts for a <code>.jpeg</code> is the only reasonable option.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://www.businessinsider.com/github-ceo-developers-embrace-ai-or-get-out-2025-8">https://www.businessinsider.com/github-ceo-developers-embrace-ai-or-get-out-2025-8</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://www.greencarreports.com/news/1100482_tesla-autopilot-the-10-most-important-things-you-need-to-know">https://www.greencarreports.com/news/1100482_tesla-autopilot-the-10-most-important-things-you-need-to-know</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://www.sciencedirect.com/science/article/pii/S0166497223000755?via%3Dihub">https://www.sciencedirect.com/science/article/pii/S0166497223000755?via%3Dihub</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2023/12/AI-and-Productivity-Report-First-Edition.pdf">https://www.microsoft.com/en-us/research/wp-content/uploads/2023/12/AI-and-Productivity-Report-First-Edition.pdf</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

</content>
<p>
  
  <a href="https://jcachada.dev/weblog/llm/">#LLM</a>
  
  <a href="https://jcachada.dev/weblog/ai/">#Ai</a>
  
  <a href="https://jcachada.dev/weblog/opinion/">#Opinion</a>
  
  <a href="https://jcachada.dev/weblog/development/">#Development</a>
  
</p>

  </main>
  <footer></footer>

    
</body>

</html>
